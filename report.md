# Отчет по проекту русскоязычного синтеза речи на базе GlowTTS

## 1) Введение
Проект направлен на обучение модели преобразования текста в речь (Text-to-Speech, TTS) для русского языка на основе корпуса Ruslan. Цель — получить устойчивый одноголосовый синтезатор, генерирующий мел-спектрограммы и аудио речевого сигнала с учетом особенностей кириллического алфавита и частоты дискретизации 22 050 Гц. Скрипты обеспечивают подготовку данных, тренировку модели GlowTTS в экосистеме Coqui TTS, а также мониторинг и запуск TensorBoard.

## 2) Используемые инструменты и архитектура

### Данные и аудиоподготовка
- Корпус: Ruslan; аудио предварительно ресэмплируется до 22 050 Гц скриптом `resample_wavs.py`, а консистентность частоты проверяется `check_sample_rate.py`.
- Формат метаданных: `metadata_train.txt` и `metadata_val.txt` (ruslan formatter) для загрузки пар «текст–аудио».
- Обработка аудио: `AudioProcessor` генерирует 80-мерные мел-спектрограммы (`fft_size=1024`, `hop_length=256`, `win_length=1024`, `spec_gain=20`, нормализация `signal_norm=True`), что соответствует стандартной фронтенд-конфигурации для вокодера Griffin–Lim.

### Текстовое представление и словарь
- Символьный (grapheme) токенизатор с кастомным `CharactersConfig`, включающим полный набор строчных и прописных кириллических символов, а также пунктуацию. Это предотвращает выпадение кириллицы, типичное для англоязычных пресетов.
- Phonemizer отключен (`use_phonemes=False`), что упрощает пайплайн и избегает ошибок транскрипции, но делает модель чувствительной к орфографии и пунктуации.

### Архитектура модели GlowTTS
- Базовая модель: GlowTTS (flow-based text-to-mel), параметрическая TTS-модель. Потоки преобразуют латентное распределение \( z \sim \mathcal{N}(0, I) \) в распределение мел-спектрограмм \( x \) через обратимое отображение \( x = f^{-1}(z) \). Максимизация правдоподобия записывается как
  \[
  \log p_X(x) = \log p_Z(f(x)) + \sum_{k} \log \left|\det J_{f_k}(x)\right|
  \]
  где \( f_k \) — последовательность шагов normalizing flow (аффинные coupling-блоки и squeeze-операции).
- Энкодер: релятивистский позиционный Transformer (`encoder_type="rel_pos_transformer"`, 6 слоев, 2 головы, FFN 768), переводящий последовательность символов в скрытые представления.
- Duration predictor: отдельная голова, моделирующая длительности символов, что обеспечивает монотонное выравнивание без внимания (Monotonic Alignment Search). Loss для длительностей добавляется к отрицательному лог-правдоподобию: \(\mathcal{L} = -\log p_X(x) + \lambda \, \text{loss}_{dur}\).
- Декодер/flow: 12 flow-блоков с kernel size 5 и 4 слоями в блоке, скрытые размеры 192–256. Используется `mean_only=True` для стабильности (отказ от масштабной части лог-детерминанта в некоторых шагах).
- Выход: мел-спектрограммы (80 каналов) далее инвертируются Griffin–Lim при синтезе через `Synthesizer` (см. `t.py`); отдельный вокодер не требуется, но может заменить Griffin–Lim для улучшения качества.

### Обучение и оптимизация
- Оптимизатор: RAdam с `lr=2e-4`, `betas=(0.9, 0.998)`, `weight_decay=1e-6`.
- Планировщик: NoamLR с увеличенным `warmup_steps=8000`, что обеспечивает медленный рост шага и сглаживает начальную фазу обучения.
- Стабилизация градиентов: `grad_clip=1.0`, mixed precision (`fp16`) и малый `batch_size=8` для экономии GPU-памяти и предотвращения взрыва градиентов. Дополнительно включена защита от блокировок логов на Windows при очистке эксперимента.
- Распределенная тренировка: бэкенд NCCL, хотя проект ориентирован на одногпу-сценарий; сохранение чекпоинтов каждые 10 000 шагов.

### Мониторинг и диагностика
- TensorBoard запускается через `view_tensorboard.py`; скрипт также анализирует финальные `loss` и `grad_norm` в `trainer_0_log.txt`, выдавая советы
по снижению lr/grad_clip при обнаружении взрывов.
- Методологические подсказки по чтению графиков (mel, alignment, duration, grad_norm) вынесены в `interpret_tensorboard_predictions.md`.
- Документ `fix_gradient_explosion.md` фиксирует примененные изменения гиперпараметров для стабилизации обучения.

### Инференс
- Пример инференса (`t.py`): `Synthesizer` загружает конфиг и чекпоинт GlowTTS, выполняет tts() для кириллического текста и сохраняет аудио. В качестве вокодера применяется встроенный Griffin–Lim; при замене на нейровокодер (HiFi-GAN) качество улучшается ценой дополнительного вычислительного шага.

### Теория Griffin–Lim (GLA)
Griffin–Lim решает задачу восстановления фазы по известной амплитуде STFT. Пусть \(S = |S|e^{j\phi}\) — целевой спектр, известен только \(|S|\). Griffin–Lim ищет сигнал \(x\), минимизирующий
\[
\min_x \; \big\|\,|\,\mathrm{STFT}(x)\,| - |S|\,\big\|_2^2,
\]
используя итеративную проекцию:
1. Прямое преобразование: \(X^{(k)} = \mathrm{STFT}(x^{(k)})\).
2. Замена амплитуды: \(\tilde X^{(k)} = |S|\; e^{j \angle X^{(k)}}\).
3. Обратное преобразование: \(x^{(k+1)} = \mathrm{ISTFT}(\tilde X^{(k)})\).

Это реализует попеременную проекцию на множество сигналов с заданной амплитудой и на множество сигналов, согласованных с окном/гопом STFT. Алгоритм гарантирует невозрастание целевой функции и сходится к локальному минимуму; качество зависит от числа итераций и параметров окна (в проекте 60 итераций, окно 1024, шаг 256). Ограничения: слышимые артефакты (металлическость, фазовый шум) и более низкое качество по сравнению с нейровокодерами, но простота и отсутствие дополнительных моделей делают GLA практичным базовым решением.

### Возможные альтернативы и сравнительный анализ
- Tacotron 2 + нейровокодер (WaveGlow/HiFi-GAN): автогрессия дает высокое качество и гибкость prosody, но медленный инференс и чувствительность к выравниванию; требует attention-масок и более строгого контроля данных.
- FastSpeech 2 + HiFi-GAN: полностью неавтогрессивный, быстрый инференс; опирается на teacher модель для длительностей или на внешний aligner; меньше проблема с эксплодящими градиентами, но чуть ниже натуральность без тщательного тюнинга.
- VITS: end-to-end потоковая генерация waveforms с VAE+GAN; убирает разделение «мел → вокодер», дает state-of-the-art качество, но сложнее в настройке, требует больше данных и аккуратной стабилизации GAN-компоненты.
- Grad-TTS / FlowTTS: диффузионные или потоковые аналоги с монотонным выравниванием; дают плавное управление длительностью и устойчивость к шуму в данных, но инференс тяжелее (несколько шагов диффузии) и обучать их дороже.
- Для текущего объема и одноголосового русскоязычного корпуса GlowTTS остается рациональным компромиссом: гарантия монотонности, закрытая формула правдоподобия и быстрый инференс без teacher моделей.

## 3) Анализ хода разработки


## 4) Результаты и выводы
- Текущее решение опирается на GlowTTS с кириллическим словарем и стабильными гиперпараметрами (пониженный lr, агрессивный grad_clip, расширенный warmup), что снижает риск взрывов градиентов и улучшает сходимость на русскоязычном корпусе.
- Подготовка данных (ресэмплинг до 22 050 Гц, проверка sample rate, фиксация путей к аудио) минимизирует несоответствия формата и снижает шум в обучении.
- Инструменты мониторинга (TensorBoard, анализ grad_norm/loss) формируют контур обратной связи: по графикам мел-спектрограмм и alignment можно оперативно обнаруживать проблемы с выравниванием и качеством спектра.
- Для дальнейшего улучшения качества синтеза целесообразно: а) подключить HiFi-GAN как вокодер; б) при наличии ресурсов сравнить с FastSpeech 2 или VITS на том же корпусе; в) расширить корпус и попробовать phonemizer с контролем ударений.

